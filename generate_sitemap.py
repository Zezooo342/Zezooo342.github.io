#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø³ÙƒØ±ÙŠØ¨Øª ØªÙˆÙ„ÙŠØ¯ sitemap.xml ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ù…ÙˆÙ‚Ø¹ GitHub Pages
ÙŠÙ‚ÙˆÙ… Ø¨ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML ÙˆÙŠÙˆÙ„Ø¯ sitemap Ø´Ø§Ù…Ù„ Ù…Ø¹ Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ù…Ù†Ø§Ø³Ø¨Ø©
"""

import os
import glob
import urllib.parse
from datetime import datetime
import xml.etree.ElementTree as ET


class SitemapGenerator:
    def __init__(self, base_url="https://zezooo342.github.io", output_file="sitemap.xml"):
        self.base_url = base_url.rstrip('/')
        self.output_file = output_file
        self.current_date = datetime.now().strftime('%Y-%m-%d')
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ£ÙˆÙ„ÙˆÙŠØ§ØªÙ‡Ø§
        self.page_priorities = {
            'index.html': {'priority': '1.0', 'changefreq': 'daily'},
            'about.html': {'priority': '0.9', 'changefreq': 'monthly'},
            'contact.html': {'priority': '0.9', 'changefreq': 'monthly'},
            'articles.html': {'priority': '0.9', 'changefreq': 'weekly'},
            'privacy.html': {'priority': '0.8', 'changefreq': 'monthly'},
            
            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            'invest-arab.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'make-money-online.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'crypto-guide.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'management.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'crypto-security.html': {'priority': '0.7', 'changefreq': 'weekly'},
            
            # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
            'ai.html': {'priority': '0.7', 'changefreq': 'weekly'},
            'article.html': {'priority': '0.7', 'changefreq': 'weekly'},
            'business-plan-simple.html': {'priority': '0.7', 'changefreq': 'weekly'},
            
            # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©
            'faq.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'team.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'reviews.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'media.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'amp-article.html': {'priority': '0.5', 'changefreq': 'weekly'},
            
            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            'Ø·Ø±Ù‚_Ø±Ø¨Ø­_Ø§Ù„Ù…Ø§Ù„_auto.html': {'priority': '0.7', 'changefreq': 'weekly'},
        }
        
        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø© Ù…Ù† sitemap
        # Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ '404.html' ÙÙ‚Ø· Ù„Ø£Ù† Ø¨Ø§Ù‚ÙŠ Ø§Ù„ØµÙØ­Ø§Øª ÙŠØ¬Ø¨ Ø£Ù† ØªØ¸Ù‡Ø± ÙÙŠ sitemap.
        # ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¬Ø°Ø± '/' ÙŠØ¯ÙˆÙŠØ§Ù‹ ÙÙŠ Ù…ÙƒØ§Ù† Ø¢Ø®Ø± ÙÙŠ Ø§Ù„ÙƒÙˆØ¯. ÙŠØªÙ… ØªØ¶Ù…ÙŠÙ† 'index.html' ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…Ø³ØªØ¨Ø¹Ø¯Ø§Ù‹.
        self.excluded_files = ['404.html']

    def get_html_files(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML ÙÙŠ Ø§Ù„Ø¬Ø°Ø±"""
        html_files = []
        for file in glob.glob("*.html"):
            if file not in self.excluded_files:
                html_files.append(file)
        return sorted(html_files)

    def get_page_info(self, filename):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙØ­Ø© (Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙˆØªÙƒØ±Ø§Ø± Ø§Ù„ØªØºÙŠÙŠØ±)"""
        if filename in self.page_priorities:
            return self.page_priorities[filename]
        else:
            # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙˆØ§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
            return {'priority': '0.6', 'changefreq': 'monthly'}

    def url_encode_filename(self, filename):
        """ØªØ±Ù…ÙŠØ² Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø®Ø§ØµØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
        return urllib.parse.quote(filename, safe='/-_')

    def generate_sitemap(self):
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ù sitemap.xml"""
        print("ğŸ” Ø¨Ø¯Ø¡ ÙØ­Øµ Ù…Ù„ÙØ§Øª HTML...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†ØµØ± Ø¬Ø°Ø± XML
        urlset = ET.Element('urlset')
        urlset.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
        urlset.set('xmlns:xsi', 'http://www.w3.org/2001/XMLSchema-instance')
        urlset.set('xsi:schemaLocation', 'http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd')

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (/)
        url_element = ET.SubElement(urlset, 'url')
        ET.SubElement(url_element, 'loc').text = f"{self.base_url}/"
        ET.SubElement(url_element, 'lastmod').text = self.current_date
        ET.SubElement(url_element, 'changefreq').text = 'daily'
        ET.SubElement(url_element, 'priority').text = '1.0'

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML
        html_files = self.get_html_files()
        print(f"ğŸ“„ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(html_files)} Ù…Ù„Ù HTML")

        # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„ Ù…Ù„Ù HTML Ø¥Ù„Ù‰ sitemap
        for filename in html_files:
            page_info = self.get_page_info(filename)
            encoded_filename = self.url_encode_filename(filename)
            
            url_element = ET.SubElement(urlset, 'url')
            ET.SubElement(url_element, 'loc').text = f"{self.base_url}/{encoded_filename}"
            # Ø§Ø³ØªØ®Ø¯Ù… ÙˆÙ‚Øª Ø¢Ø®Ø± ØªØ¹Ø¯ÙŠÙ„ ÙØ¹Ù„ÙŠ Ù„Ù„Ù…Ù„Ù
            try:
                lastmod_date = datetime.fromtimestamp(os.path.getmtime(filename)).strftime('%Y-%m-%d')
            except FileNotFoundError:
                lastmod_date = self.current_date
            ET.SubElement(url_element, 'lastmod').text = lastmod_date
            ET.SubElement(url_element, 'changefreq').text = page_info['changefreq']
            ET.SubElement(url_element, 'priority').text = page_info['priority']
            
            print(f"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ©: {filename} (Ø£ÙˆÙ„ÙˆÙŠØ©: {page_info['priority']})")

        # ÙƒØªØ§Ø¨Ø© XML Ø¥Ù„Ù‰ Ù…Ù„Ù
        tree = ET.ElementTree(urlset)
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙ†Ø³ÙŠÙ‚ Ø¬Ù…ÙŠÙ„ Ù„Ù„Ù€ XML
        self.indent(urlset)
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„ØªØµØ±ÙŠØ­ XML
        with open(self.output_file, 'wb') as f:
            f.write(b'<?xml version="1.0" encoding="UTF-8"?>\n')
            tree.write(f, encoding='utf-8', xml_declaration=False)

        print(f"ğŸ‰ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {self.output_file} Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {len(html_files) + 1}")  # +1 Ù„Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

    def indent(self, elem, level=0):
        """Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§ÙØ§Øª Ù„ØªÙ†Ø³ÙŠÙ‚ XML"""
        i = "\n" + level * "  "
        if len(elem):
            if not elem.text or not elem.text.strip():
                elem.text = i + "  "
            if not elem.tail or not elem.tail.strip():
                elem.tail = i
            for child in elem:
                self.indent(child, level+1)
                if not child.tail or not child.tail.strip():
                    child.tail = i
        else:
            if level and (not elem.tail or not elem.tail.strip()):
                elem.tail = i

    def validate_sitemap(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© sitemap Ø§Ù„Ù…ÙˆÙ„Ø¯"""
        if not os.path.exists(self.output_file):
            print("âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù sitemap")
            return False
            
        try:
            tree = ET.parse(self.output_file)
            root = tree.getroot()
            urls = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url')
            print(f"âœ… ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† sitemap: {len(urls)} Ø±Ø§Ø¨Ø·")
            return True
        except ET.ParseError as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ XML: {e}")
            return False


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸš€ Ù…ÙˆÙ„Ø¯ sitemap.xml Ù„Ù„Ù…ÙˆÙ‚Ø¹")
    print("=" * 40)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ sitemap
    generator = SitemapGenerator()
    
    # ØªÙˆÙ„ÙŠØ¯ sitemap
    generator.generate_sitemap()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©
    if generator.validate_sitemap():
        print("\nâœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ sitemap.xml Ø¨Ù†Ø¬Ø§Ø­!")
        print("ğŸ”— ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹")
    else:
        print("\nâŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ sitemap ØµØ­ÙŠØ­")


if __name__ == "__main__":
    main()