#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø³ÙƒØ±ÙŠØ¨Øª ØªÙˆÙ„ÙŠØ¯ sitemap.xml ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ù…ÙˆÙ‚Ø¹ GitHub Pages
ÙŠÙ‚ÙˆÙ… Ø¨ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML ÙˆÙŠÙˆÙ„Ø¯ sitemap Ø´Ø§Ù…Ù„ Ù…Ø¹ Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ù…Ù†Ø§Ø³Ø¨Ø©
"""

import os
import glob
import urllib.parse
from datetime import datetime
import xml.etree.ElementTree as ET


class SitemapGenerator:
    def __init__(self, base_url="https://zezooo342.github.io", output_file="sitemap.xml"):
        self.base_url = base_url.rstrip('/')
        self.output_file = output_file
        self.current_date = datetime.now().strftime('%Y-%m-%d')
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ£ÙˆÙ„ÙˆÙŠØ§ØªÙ‡Ø§ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ©
        self.page_priorities = {
            # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù…ÙˆÙ‚Ø¹ - Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ©
            'index.html': {'priority': '1.0', 'changefreq': 'daily'},
            'about.html': {'priority': '0.9', 'changefreq': 'monthly'},
            'contact.html': {'priority': '0.9', 'changefreq': 'monthly'},
            'articles.html': {'priority': '0.9', 'changefreq': 'weekly'},
            
            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø§Ù„ÙŠ ÙˆØ§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠ - Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ©
            'invest-arab.html': {'priority': '0.9', 'changefreq': 'weekly'},
            'make-money-online.html': {'priority': '0.9', 'changefreq': 'weekly'},
            'crypto-guide.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'management.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'crypto-security.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'ØªØ¯Ø§ÙˆÙ„_Ø§Ù„Ø£Ø³Ù‡Ù….html': {'priority': '0.8', 'changefreq': 'weekly'},
            'Ø§Ù„Ø¹Ù…Ù„Ø§Øª_Ø§Ù„Ø±Ù‚Ù…ÙŠØ©.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±_ÙÙŠ_Ù…Øµ.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'Ø§Ù„ØªØ³ÙˆÙŠÙ‚_Ø¨Ø§Ù„Ø¹Ù…ÙˆÙ„.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'Ù…Ø´Ø§Ø±ÙŠØ¹_ØµØºÙŠØ±Ø©_Ù„Ù„.html': {'priority': '0.8', 'changefreq': 'weekly'},
            
            # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ - Ø£ÙˆÙ„ÙˆÙŠØ© Ù…ØªÙˆØ³Ø·Ø© Ø¹Ø§Ù„ÙŠØ©
            'ai.html': {'priority': '0.8', 'changefreq': 'weekly'},
            'article.html': {'priority': '0.7', 'changefreq': 'weekly'},
            'business-plan-simple.html': {'priority': '0.7', 'changefreq': 'weekly'},
            
            # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ© - Ø£ÙˆÙ„ÙˆÙŠØ© Ù…ØªÙˆØ³Ø·Ø©
            'privacy.html': {'priority': '0.7', 'changefreq': 'monthly'},
            'terms.html': {'priority': '0.7', 'changefreq': 'monthly'},
            'disclaimer.html': {'priority': '0.7', 'changefreq': 'monthly'},
            'faq.html': {'priority': '0.6', 'changefreq': 'monthly'},
            
            # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©
            'team.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'reviews.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'media.html': {'priority': '0.6', 'changefreq': 'monthly'},
            'amp-article.html': {'priority': '0.5', 'changefreq': 'weekly'},
            
            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…ØªØ®ØµØµ - Ø£ÙˆÙ„ÙˆÙŠØ© Ù…ØªÙˆØ³Ø·Ø© Ø¹Ø§Ù„ÙŠØ©
            'Ø·Ø±Ù‚_Ø±Ø¨Ø­_Ø§Ù„Ù…Ø§Ù„_auto.html': {'priority': '0.8', 'changefreq': 'weekly'},
        }
        
        # ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        self.content_categories = {
            'high_priority_articles': {
                'keywords': ['AI_Tools', 'Top_10', 'CEO', 'profit', 'money', 'investment', 'crypto'],
                'priority': '0.8',
                'changefreq': 'weekly'
            },
            'business_articles': {
                'keywords': ['Business', 'CEO', 'Company', 'Startup', 'Management'],
                'priority': '0.7',
                'changefreq': 'weekly'
            },
            'tech_articles': {
                'keywords': ['AI', 'Tech', 'Data', 'System'],
                'priority': '0.7',
                'changefreq': 'weekly'
            },
            'general_articles': {
                'keywords': [],  # fallback for other articles
                'priority': '0.6',
                'changefreq': 'monthly'
            }
        }
        
        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø© Ù…Ù† sitemap
        self.excluded_files = ['404.html', 'index.html']  # Ø§Ø³ØªØ«Ù†Ø§Ø¡ index.html Ù„Ø£Ù†Ù†Ø§ Ù†Ø¶ÙŠÙ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙŠØ¯ÙˆÙŠØ§Ù‹

    def get_html_files(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML ÙÙŠ Ø§Ù„Ø¬Ø°Ø±"""
        html_files = []
        for file in glob.glob("*.html"):
            if file not in self.excluded_files:
                html_files.append(file)
        return sorted(html_files)

    def get_page_info(self, filename):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙØ­Ø© Ù…Ø¹ ØªØµÙ†ÙŠÙ Ø°ÙƒÙŠ (Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙˆØªÙƒØ±Ø§Ø± Ø§Ù„ØªØºÙŠÙŠØ±)"""
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù…ÙØ¹Ø±ÙÙ‘Ù Ù…Ø³Ø¨Ù‚Ø§Ù‹ØŒ Ø§Ø³ØªØ®Ø¯Ù… ØªÙ„Ùƒ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
        if filename in self.page_priorities:
            return self.page_priorities[filename]
        
        # ØªØµÙ†ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„Ø§Ø³Ù…
        filename_lower = filename.lower()
        
        # ÙØ­Øµ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        for category, config in self.content_categories.items():
            if config['keywords']:  # ØªØ¬Ù†Ø¨ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©
                for keyword in config['keywords']:
                    if keyword.lower() in filename_lower:
                        print(f"ğŸ“Š ØªØµÙ†ÙŠÙ Ø°ÙƒÙŠ: {filename} -> ÙØ¦Ø© {category} (Ø£ÙˆÙ„ÙˆÙŠØ©: {config['priority']})")
                        return {'priority': config['priority'], 'changefreq': config['changefreq']}
        
        # Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø£Ø¹Ø·Ù‡Ø§ Ø£ÙˆÙ„ÙˆÙŠØ© Ø£Ø¹Ù„Ù‰
        if any(ord(char) >= 0x0600 and ord(char) <= 0x06FF for char in filename):
            print(f"ğŸ”¤ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ: {filename} -> Ø£ÙˆÙ„ÙˆÙŠØ© 0.7")
            return {'priority': '0.7', 'changefreq': 'weekly'}
        
        # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙˆØ§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
        return self.content_categories['general_articles']

    def url_encode_filename(self, filename):
        """ØªØ±Ù…ÙŠØ² Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø®Ø§ØµØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
        return urllib.parse.quote(filename, safe='/-_')

    def generate_sitemap(self):
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ù sitemap.xml Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ©"""
        print("ğŸ” Ø¨Ø¯Ø¡ ÙØ­Øµ Ù…Ù„ÙØ§Øª HTML Ù…Ø¹ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø°ÙƒÙŠ...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†ØµØ± Ø¬Ø°Ø± XML Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØµØ­ÙŠØ­Ø©
        urlset = ET.Element('urlset')
        urlset.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
        urlset.set('xmlns:xsi', 'http://www.w3.org/2001/XMLSchema-instance')
        urlset.set('xsi:schemaLocation', 'http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd')

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (/) - Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù‚ØµÙˆÙ‰
        print("ğŸ  Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©...")
        url_element = ET.SubElement(urlset, 'url')
        ET.SubElement(url_element, 'loc').text = f"{self.base_url}/"
        ET.SubElement(url_element, 'lastmod').text = self.current_date
        ET.SubElement(url_element, 'changefreq').text = 'daily'
        ET.SubElement(url_element, 'priority').text = '1.0'

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML Ù…Ø¹ Ø§Ù„ÙØ±Ø²
        html_files = self.get_html_files()
        print(f"ğŸ“„ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(html_files)} Ù…Ù„Ù HTML")

        # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£ÙØ¶Ù„
        priority_counts = {'1.0': 1, '0.9': 0, '0.8': 0, '0.7': 0, '0.6': 0, '0.5': 0}
        
        # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„ Ù…Ù„Ù HTML Ø¥Ù„Ù‰ sitemap Ù…Ø¹ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­Ø³Ù†
        for filename in html_files:
            page_info = self.get_page_info(filename)
            encoded_filename = self.url_encode_filename(filename)
            
            url_element = ET.SubElement(urlset, 'url')
            ET.SubElement(url_element, 'loc').text = f"{self.base_url}/{encoded_filename}"
            
            # Ø§Ø³ØªØ®Ø¯Ù… ÙˆÙ‚Øª Ø¢Ø®Ø± ØªØ¹Ø¯ÙŠÙ„ ÙØ¹Ù„ÙŠ Ù„Ù„Ù…Ù„Ù Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
            try:
                lastmod_date = datetime.fromtimestamp(os.path.getmtime(filename)).strftime('%Y-%m-%d')
                print(f"ğŸ“… ØªØ§Ø±ÙŠØ® ÙØ¹Ù„ÙŠ Ù„Ù€ {filename}: {lastmod_date}")
            except (OSError, FileNotFoundError) as e:
                lastmod_date = self.current_date
                print(f"âš ï¸  Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù€ {filename}: {e}")
                
            ET.SubElement(url_element, 'lastmod').text = lastmod_date
            ET.SubElement(url_element, 'changefreq').text = page_info['changefreq']
            ET.SubElement(url_element, 'priority').text = page_info['priority']
            
            # ØªØ¬Ù…ÙŠØ¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª
            priority_counts[page_info['priority']] = priority_counts.get(page_info['priority'], 0) + 1
            
            print(f"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ©: {filename} (Ø£ÙˆÙ„ÙˆÙŠØ©: {page_info['priority']}, ØªØ­Ø¯ÙŠØ«: {page_info['changefreq']})")

        # ÙƒØªØ§Ø¨Ø© XML Ø¥Ù„Ù‰ Ù…Ù„Ù Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        tree = ET.ElementTree(urlset)
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙ†Ø³ÙŠÙ‚ Ø¬Ù…ÙŠÙ„ ÙˆÙ…Ù†Ø³Ù‚ Ù„Ù„Ù€ XML
        self.indent(urlset)
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„ØªØµØ±ÙŠØ­ XML ÙˆØ§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„ØµØ­ÙŠØ­
        try:
            with open(self.output_file, 'w', encoding='utf-8') as f:
                f.write('<?xml version="1.0" encoding="UTF-8"?>\n')
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ Ù…Ø¹ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµØ­ÙŠØ­
                xml_string = ET.tostring(urlset, encoding='unicode')
                f.write(xml_string)
            
            print(f"ğŸ‰ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {self.output_file} Ø¨Ù†Ø¬Ø§Ø­!")
            print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {len(html_files) + 1}")  # +1 Ù„Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª
            print("\nğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª:")
            for priority, count in sorted(priority_counts.items(), key=lambda x: float(x[0]), reverse=True):
                if count > 0:
                    print(f"   Ø£ÙˆÙ„ÙˆÙŠØ© {priority}: {count} ØµÙØ­Ø©")
                    
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            raise

    def indent(self, elem, level=0):
        """Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§ÙØ§Øª Ù„ØªÙ†Ø³ÙŠÙ‚ XML Ù…Ø¹ Ø¶Ù…Ø§Ù† ØªÙ†Ø³ÙŠÙ‚ Ù…ØªØ³Ù‚"""
        i = "\n" + level * "  "
        if len(elem):
            if not elem.text or not elem.text.strip():
                elem.text = i + "  "
            if not elem.tail or not elem.tail.strip():
                elem.tail = i
            for child in elem:
                self.indent(child, level+1)
            if not child.tail or not child.tail.strip():
                child.tail = i
        else:
            if level and (not elem.tail or not elem.tail.strip()):
                elem.tail = i
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø£Ø®ÙŠØ±
        if level == 0:
            elem.tail = "\n"

    def validate_sitemap(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ù† ØµØ­Ø© sitemap Ø§Ù„Ù…ÙˆÙ„Ø¯"""
        print("\nğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ù† sitemap...")
        
        if not os.path.exists(self.output_file):
            print("âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù sitemap")
            return False
            
        try:
            # Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ XML
            tree = ET.parse(self.output_file)
            root = tree.getroot()
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† namespace
            expected_ns = 'http://www.sitemaps.org/schemas/sitemap/0.9'
            if root.tag != f'{{{expected_ns}}}urlset':
                print(f"âš ï¸  ØªØ­Ø°ÙŠØ±: namespace ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø¬Ø°Ø±")
            
            urls = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url')
            locs = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}loc')
            
            print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(urls)} URL ÙÙŠ sitemap")
            print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(locs)} Ø¹Ù†ØµØ± loc")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª ÙˆØ§Ù„ØµÙŠØºØ©
            priorities = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}priority')
            priority_values = [float(p.text) for p in priorities if p.text]
            
            if priority_values:
                print(f"ğŸ“Š Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª: {min(priority_values):.1f} - {max(priority_values):.1f}")
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£ÙˆÙ„ÙˆÙŠØ© 1.0 Ù„Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
                if 1.0 in priority_values:
                    print("âœ… Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù‡Ø§ Ø£ÙˆÙ„ÙˆÙŠØ© 1.0")
                else:
                    print("âš ï¸  ØªØ­Ø°ÙŠØ±: Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙØ­Ø© Ø¨Ø£ÙˆÙ„ÙˆÙŠØ© 1.0")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ§Ø±ÙŠØ® Ø¢Ø®Ø± ØªØ¹Ø¯ÙŠÙ„
            lastmods = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}lastmod')
            if lastmods:
                print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(lastmods)} ØªØ§Ø±ÙŠØ® lastmod")
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙŠØºØ© Ø§Ù„ØªØ§Ø±ÙŠØ®
                valid_dates = 0
                for lastmod in lastmods[:5]:  # ÙØ­Øµ Ø£ÙˆÙ„ 5 ÙÙ‚Ø· Ù„ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª
                    try:
                        datetime.strptime(lastmod.text, '%Y-%m-%d')
                        valid_dates += 1
                    except ValueError:
                        print(f"âš ï¸  ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­: {lastmod.text}")
                
                if valid_dates > 0:
                    print(f"âœ… ØµÙŠØºØ© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ØµØ­ÙŠØ­Ø© (ØªÙ… ÙØ­Øµ {valid_dates}/{min(5, len(lastmods))})")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
            file_size = os.path.getsize(self.output_file)
            print(f"ğŸ“ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {file_size:,} Ø¨Ø§ÙŠØª")
            
            if file_size > 50 * 1024 * 1024:  # 50MB Ø­Ø¯ Google
                print("âš ï¸  ØªØ­Ø°ÙŠØ±: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± (Ø£ÙƒØ«Ø± Ù…Ù† 50MB)")
            elif file_size > 10 * 1024 * 1024:  # 10MB ØªØ­Ø°ÙŠØ± Ù…Ø¨ÙƒØ±
                print("âš ï¸  Ù…Ù„Ø§Ø­Ø¸Ø©: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ù†Ø³Ø¨ÙŠØ§Ù‹ (Ø£ÙƒØ«Ø± Ù…Ù† 10MB)")
            else:
                print("âœ… Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù†Ø§Ø³Ø¨")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙÙƒØ±Ø±Ø©
            loc_texts = [loc.text for loc in locs]
            unique_locs = set(loc_texts)
            if len(loc_texts) != len(unique_locs):
                duplicates = len(loc_texts) - len(unique_locs)
                print(f"âš ï¸  ØªØ­Ø°ÙŠØ±: {duplicates} Ø±Ø§Ø¨Ø· Ù…ÙÙƒØ±Ø±")
            else:
                print("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙƒØ±Ø±Ø©")
            
            print(f"ğŸ¯ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø©: sitemap ØµØ­ÙŠØ­ Ù…Ø¹ {len(urls)} Ø±Ø§Ø¨Ø·")
            return True
            
        except ET.ParseError as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ XML: {e}")
            return False
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚: {e}")
            return False


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸš€ Ù…ÙˆÙ„Ø¯ sitemap.xml Ù„Ù„Ù…ÙˆÙ‚Ø¹")
    print("=" * 40)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ sitemap
    generator = SitemapGenerator()
    
    # ØªÙˆÙ„ÙŠØ¯ sitemap
    generator.generate_sitemap()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©
    if generator.validate_sitemap():
        print("\nâœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ sitemap.xml Ø¨Ù†Ø¬Ø§Ø­!")
        print("ğŸ”— ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹")
    else:
        print("\nâŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ sitemap ØµØ­ÙŠØ­")


if __name__ == "__main__":
    main()